{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e6461d87001e862",
   "metadata": {},
   "source": [
    "# Router Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62d397b1740a44a",
   "metadata": {},
   "source": [
    "![Router Engine Diagram](assets/router-engine.png)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ba604ae-a7d1-42cc-9306-6e0e800e77cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
    "os.environ['ATHINA_API_KEY'] = \"IhrJrr0krTMRA9ogqi5aaD4ZuYuvMcdG\"\n",
    "\n",
    "\n",
    "INFERENCE_SERVER_URL = \"http://localhost:8989\"\n",
    "# MODEL_NAME = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\n",
    "MODEL_NAME = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\"\n",
    "API_KEY= \"alanliuxiang\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=API_KEY,\n",
    "    openai_api_base= f\"{INFERENCE_SERVER_URL}/v1\",\n",
    "    model_name=MODEL_NAME,\n",
    "    top_p=0.92,\n",
    "    temperature=0.01,\n",
    "    max_tokens=512,\n",
    "    presence_penalty=1.03,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a875bef9eddbb491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999719423b3dad99",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7218ad8a0ccd44cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents\n",
    "documents = SimpleDirectoryReader(input_files=['./assets/metagpt.pdf']).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bb31bd94058708",
   "metadata": {},
   "source": [
    "### Define LLM and Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7925224fe90eb6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "519117c74d203faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "Settings.llm = llm\n",
    "# Settings.embed_model = OpenAIEmbedding(model='text-embedding-ada-002')\n",
    "Settings.embed_model = HuggingFaceEmbedding()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6661d7b7006308",
   "metadata": {},
   "source": [
    "### Define Summary Index and Vector Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c52137530dd1b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
    "\n",
    "summary_index = SummaryIndex(nodes)\n",
    "vector_index = VectorStoreIndex(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9738741c76bcebad",
   "metadata": {},
   "source": [
    "### Define Query Engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "243e172193e5f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode='tree_summarize',\n",
    "    use_async=True\n",
    ")\n",
    "\n",
    "vector_query_engine = vector_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "891f3c7062a308d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        'Useful for summarization questions related to MetaGPT'\n",
    "    )\n",
    ")\n",
    "\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=vector_query_engine,\n",
    "    description=(\n",
    "        'Useful for retrieving specific context from MetaGPT'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab526e80b72ebc4",
   "metadata": {},
   "source": [
    "### Define Router Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7783d34f30a8a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors import LLMSingleSelector\n",
    "\n",
    "query_engine = RouterQueryEngine(\n",
    "    selector=LLMSingleSelector.from_defaults(),\n",
    "    query_engine_tools=[\n",
    "        summary_tool,\n",
    "        vector_tool\n",
    "    ],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc19b4910e47a480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"choice\": 1,\n",
      "        \"reason\": \"The question asks for a summary of a document, which aligns with the purpose of choice (1) as it is designed for summarization tasks related to MetaGPT.\"\n",
      "    }\n",
      "]\n",
      "```\u001b[1;3;38;5;200mSelecting query engine 0: The question asks for a summary of a document, which aligns with the purpose of choice (1) as it is designed for summarization tasks related to MetaGPT..\n",
      "\u001b[0m\n",
      "\n",
      "**Summary of MetaGPT Document**\n",
      "\n",
      "MetaGPT is a meta-programming framework designed to enhance multi-agent collaborations using Large Language Models (LLMs). It addresses the challenge of complex problem-solving by incorporating human-like Standardized Operating Procedures (SOPs), which streamline workflows and reduce errors caused by naive chaining of LLMs. The framework assigns diverse roles to agents, enabling efficient task decomposition and structured communication. Each agent operates with defined goals and constraints, adhering to SOPs that guide their actions and interactions. MetaGPT's structured approach ensures consistent and accurate task execution, validated by state-of-the-art performance in benchmarks, achieving high success rates and efficient resource utilization. This innovative framework significantly advances the field of\n",
      "\n",
      "The document introduces MetaGPT, a novel meta-programming framework designed to enhance the problem-solving capabilities of multi-agent systems using Large Language Models (LLMs). MetaGPT models a group of agents as a simulated software company, incorporating role specialization, workflow management, and efficient sharing mechanisms like message pools and subscriptions. It also features an executable feedback mechanism to improve code generation quality during runtime, setting it apart from other methods like AutoGPT, LangChain, AgentVerse, and ChatDev.\n",
      "\n",
      "Key findings include:\n",
      "\n",
      "1. **Role Specialization**: The ablation study demonstrates that adding roles beyond the Engineer\n",
      "\n",
      "The document presents a comprehensive exploration of self-improvement mechanisms in artificial intelligence, tracing their evolution from theoretical foundations to modern applications. It begins with early conceptualizations by pioneers like Good and Schmidhuber, who laid the groundwork for recursive self-improvement in the mid-20th century. The discussion progresses through concrete implementations in the 1990s and culminates in advanced, mathematically optimal self-referential systems by the turn of the millennium. \n",
      "\n",
      "Recent advancements leverage large language models (LLMs) to enhance AI's ability to adapt and improve through tasks like prompt engineering. These innovations build on earlier work, demonstrating how AI can recursively refine its own processes, leading to more efficient learning and problem-solving. The document highlights the integration of these mechanisms into contemporary AI systems, emphasizing their potential for continuous self\n",
      "\n",
      "The document presents MetaGPT, a framework for software development that emphasizes self-improvement and collaboration among agents. It highlights a recursive self-improvement mechanism where agents adjust their behavior based on past experiences, enhancing their performance over time. The framework also introduces a multi-agent economy model, inspired by principles of supply and demand, enabling efficient collaboration and credit assignment among agents. Additionally, the document provides a detailed example of developing a Python GUI application, demonstrating the practical application of the framework. It concludes with a discussion of the SoftwareDev dataset, which includes diverse software development tasks.\n",
      "\n",
      "The document describes a QA Engineer's role in generating and reviewing unit test code, illustrated with an example test script for a ColorPicker class. It also introduces MetaGPT, a framework for software development tasks, which demonstrates superior performance compared to other tools like AutoGPT and Langchain, achieving an average executability score of 3.9. Experiments show MetaGPT's effectiveness with different LLMs, particularly GPT-4, and\n",
      "\n",
      "The document presents a summary of 70 tasks evaluated using MetaGPT without feedback in the SoftwareDev domain. Each task is analyzed with code, documentation, and cost statistics, along with any encountered issues. Key findings include:\n",
      "\n",
      "- **Task Statistics**: On average, tasks involved 4.71 code files, 191.57 lines of code, and 3.00 documentation files. Code execution times averaged 516.71 seconds, with completion costs around $1.12.\n",
      "- **Common Issues**: Frequently reported problems included TypeErrors, missing dependencies, and file-related errors. Dependency errors were the most common issue, affecting 3.36 tasks on average.\n",
      "- **Performance**: The average number of prompt tokens used was 26,626.86, and completion tokens averaged 6,218.00.\n",
      "\n",
      "Overall, the results highlight the effectiveness of MetaGPT in generating code while identifying recurring challenges in task execution.\n",
      "\n",
      "The document introduces MetaGPT, a meta-programming framework designed to enhance multi-agent collaborations using Large Language Models (LLMs). It streamlines workflows by incorporating human-like Standardized Operating Procedures (SOPs), reducing errors and improving task execution. The framework assigns diverse roles to agents, enabling efficient task decomposition and structured communication. Key features include role specialization, message pools, subscriptions, and an executable feedback mechanism for real-time improvements. MetaGPT outperforms other methods like AutoGPT, achieving an average executability score of 3.9. The document evaluates 70 tasks in the SoftwareDev domain, highlighting an average of 4.71 code files, 191.57 lines of code, and 3.00 documentation files per task. Common challenges include TypeErrors and missing dependencies, with dependency errors being the most frequent issue. Overall, MetaGPT demonstrates effective code generation but faces recurring execution challenges.\n",
      "\n",
      "The document introduces MetaGPT, a meta-programming framework designed to enhance multi-agent collaborations using Large Language Models (LLMs). It streamlines workflows by incorporating human-like Standardized Operating Procedures (SOPs), reducing errors and improving task execution. The framework assigns diverse roles to agents, enabling efficient task decomposition and structured communication. Key features include role specialization, message pools, subscriptions, and an executable feedback mechanism for real-time improvements. MetaGPT outperforms other methods like AutoGPT, achieving an average executability score of 3.9. The document evaluates 70 tasks in the SoftwareDev domain, highlighting an average of 4.71 code files, 191.57 lines of code, and 3.00 documentation files per task. Common challenges include TypeErrors and missing dependencies, with dependency errors being the most frequent issue. Overall, MetaGPT demonstrates effective code generation but faces recurring execution challenges.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query('Summarize the document')\n",
    "\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "481216d966dc05dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response.source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e57a35b5589ecfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"choice\": 2,\n",
      "        \"reason\": \"The question asks for specific details on how agents share information, which requires retrieving specific context rather than a general summary.\"\n",
      "    }\n",
      "]\n",
      "```\u001b[1;3;38;5;200mSelecting query engine 1: The question asks for specific details on how agents share information, which requires retrieving specific context rather than a general summary..\n",
      "\u001b[0m\n",
      "\n",
      "Agents share information through a publish-subscribe mechanism. They publish structured outputs, such as documents and diagrams, into a shared message pool. Each agent can then subscribe to receive only the information relevant to their role, allowing them to efficiently access necessary details without unnecessary distractions.\n",
      "\n",
      "Agents share information through a publish-subscribe mechanism. They publish structured outputs, such as documents and diagrams, into a shared message pool. Each agent can then subscribe to receive only the information relevant to their role, allowing them to efficiently access necessary details without unnecessary distractions.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query('How do agents share information with other agents ?')\n",
    "\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c96b85ba23b569e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response.source_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c3cfd7419ab91f",
   "metadata": {},
   "source": [
    "### Given a file path create a router query engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1c22cae0d09436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, SummaryIndex, VectorStoreIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors import LLMSingleSelector\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "\n",
    "def get_router_query_engine(file_path: str, llm = None, embed_model = None):\n",
    "    \"\"\"Get router query engine\"\"\"\n",
    "    llm = llm\n",
    "    embed_model = embed_model\n",
    "    \n",
    "    # Load documents\n",
    "    documents = SimpleDirectoryReader(input_files=[file_path]).load_data()\n",
    "    \n",
    "    splitter = SentenceSplitter(chunk_size=1024)\n",
    "    nodes = splitter.get_nodes_from_documents(documents)\n",
    "    \n",
    "    summary_index = SummaryIndex(nodes)\n",
    "    vector_index = VectorStoreIndex(nodes)\n",
    "    \n",
    "    summary_query_engine = summary_index.as_query_engine(\n",
    "        response_mode='tree_summarize',\n",
    "        use_async=True,\n",
    "        llm=llm\n",
    "    )\n",
    "    vector_query_engine = vector_index.as_query_engine()\n",
    "\n",
    "    summary_tool = QueryEngineTool.from_defaults(\n",
    "        query_engine=summary_query_engine,\n",
    "        description=(\n",
    "            'Useful for summarization questions related to MetaGPT'\n",
    "        )\n",
    "    )\n",
    "    vector_tool = QueryEngineTool.from_defaults(\n",
    "        query_engine=vector_query_engine,\n",
    "        description=(\n",
    "            'Useful for retrieving specific context from MetaGPT'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    query_engine = RouterQueryEngine(\n",
    "        selector=LLMSingleSelector.from_defaults(),\n",
    "        query_engine_tools=[\n",
    "            summary_tool,\n",
    "            vector_tool\n",
    "        ],\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    return query_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bd13e2f490163ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = get_router_query_engine('./assets/metagpt.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94e58f1b031fc5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"choice\": 2,\n",
      "        \"reason\": \"The question requires explaining the results of an ablation study, which involves analyzing specific components and their effects. Choice (2) is relevant as it pertains to retrieving detailed context necessary for such an explanation.\"\n",
      "    }\n",
      "]\n",
      "```\u001b[1;3;38;5;200mSelecting query engine 1: The question requires explaining the results of an ablation study, which involves analyzing specific components and their effects. Choice (2) is relevant as it pertains to retrieving detailed context necessary for such an explanation..\n",
      "\u001b[0m\n",
      "\n",
      "The ablation study results demonstrate how different factors influence MetaGPT's performance. When using more advanced language models like GPT-4, MetaGPT achieves higher success rates in benchmarks, such as 87.7% in HumanEval, outperforming previous methods. Additionally, providing detailed instructions yields better task execution, though high-level prompts still produce effective results with comparable quality. These findings highlight MetaGPT's robustness across varying input levels and backend models, contributing to its superior performance in software development tasks.\n",
      "\n",
      "The ablation study results demonstrate how different factors influence MetaGPT's performance. When using more advanced language models like GPT-4, MetaGPT achieves higher success rates in benchmarks, such as 87.7% in HumanEval, outperforming previous methods. Additionally, providing detailed instructions yields better task execution, though high-level prompts still produce effective results with comparable quality. These findings highlight MetaGPT's robustness across varying input levels and backend models, contributing to its superior performance in software development tasks.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query('Explain ablation study results')\n",
    "\n",
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
